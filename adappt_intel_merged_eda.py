# -*- coding: utf-8 -*-
"""adappt_intel_merged_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zmIK0l9J2zwnoU5vrgsQxeniGKuszI0y
"""

import matplotlib.pyplot as plt
import random
import pandas as pd
import seaborn as sns
import numpy as np

# Load the updated dataset
ip_filename = str(input("enter the updated data file: "))
ip_filename = ip_filename+".csv"
df_updated = pd.read_csv(ip_filename)
df_details = pd.read_csv('details.csv')

"""# Data Processing Steps

The code follows these steps:

1. Load the 'updated_data.csv' and 'details.csv' files into separate DataFrames.
2. Convert the 'Datetime' column in the 'updated_data' DataFrame to datetime format.
3. Create a new DataFrame to store the resampled data.
4. Iterate through each sensor in the 'details' DataFrame. For each sensor:
    - Extract the data for the current sensor from the 'updated_data' DataFrame and set 'Datetime' as the index.
    - Add the timezone offset to the 'Datetime' index.
    - Resample the data to 10-minute intervals, summing the 'peopleCount' values within each interval.
    - Add the resampled data to the resampled DataFrame.
5. Reset the index of the resampled DataFrame.
6. Merge the resampled DataFrame with the 'details' DataFrame based on the 'sensorId' column.
7. Display the first few rows of the final DataFrame.

These steps outline the data processing performed in the code.

"""

# Create a new dataframe for the resampled data
df_resampled = pd.DataFrame()

# Iterate through each sensor in the updated dataframe
for sensorId in df_updated['sensorId'].unique():
    # Extract the data for the current sensor
    df_sensor = df_updated[df_updated['sensorId'] == sensorId].copy()

    # Convert 'Datetime' to datetime format and set as index
    df_sensor['Datetime'] = pd.to_datetime(df_sensor['Datetime'])
    df_sensor.set_index('Datetime', inplace=True)


    # Resample to 10-minute intervals, summing 'peopleCount' within each interval
    df_sensor_resampled = df_sensor.resample('10T').agg({
        'sensorId': 'first',  # use 'first' to include 'sensorId' in the resampled data
        'peopleCount': 'sum'  # sum 'peopleCount' within each interval
    })

    # Add the resampled data to the resampled dataframe
    df_resampled = pd.concat([df_resampled, df_sensor_resampled])

# Reset the index
df_resampled.reset_index(inplace=True)

# Merge the resampled data with the sensor details data
df_final = pd.merge(df_resampled, df_details, on='sensorId')

# Add the 'timezoneOffset' to the 'Datetime' column to adjust the timestamps
df_final['timezoneOffset'] = df_final['timezoneOffset'] / (60 * 60 * 1000) # convert ms to hours
df_final['Datetime'] = df_final['Datetime'] + pd.to_timedelta(df_final['timezoneOffset'], unit='h')

# Display the first few rows of the final dataframe
df_final.head()

"""##NOTE:
# Modification of the `peopleCount` Column

During the merging process, an issue arose with treating the `peopleCount` column as a binary value (0 or 1) to indicate the presence or absence of people. This approach did not accurately represent the actual presence of people, especially when resampling the data to different time intervals.

To address this issue and ensure a more accurate representation, a modification was made to the `peopleCount` column. Instead of a binary value, the `peopleCount` column now represents the number of intervals (within the resampled time interval) during which a person was present.

This modification allows for a more granular representation of the data, accounting for varying intervals and avoiding the erroneous assumption of a single binary value. By counting the number of intervals a person was present, we can capture the duration and frequency of their presence more accurately.

This change enables a more precise analysis of the data, taking into account the varying intervals of sensor readings and providing a more realistic view of people's presence over time.

P.S: Now peopleCount ranges from 0-10, since there are sensors capturing data for 1-min intervals and 2-min intervals.

#**Save Merged File**
"""

# Save the merged dataframe to a CSV file
filename = str(input("enter the filename for the new merged csv file: "))
filename = filename+".csv"
df_final.to_csv(filename, index=False)

"""#**Miscellaneous Analysis**

##**EDA**
"""

data = pd.read_csv(filename)

# Get the basic information of the data
data_info = data.info()

# Generate summary statistics for the categorical columns
data.describe(include=['O'])

# Get the summary statistics of the numerical columns
summary_statistics = data.describe(include=[np.number])

# Count the number of unique values in each column
unique_counts = data.nunique()

# Convert Datetime column to datetime data type
data['Datetime'] = pd.to_datetime(data['Datetime'])

# Extract date features
data['hour'] = data['Datetime'].dt.hour
data['dayofweek'] = data['Datetime'].dt.dayofweek
data['dayofyear'] = data['Datetime'].dt.dayofyear
data['month'] = data['Datetime'].dt.month
data['year'] = data['Datetime'].dt.year
data['weekofyear'] = data['Datetime'].dt.isocalendar().week

# Plot histogram of peopleCount
plt.figure(figsize=(10,6))
sns.histplot(data['peopleCount'], kde=True)
plt.title('Distribution of peopleCount')
plt.xlabel('peopleCount')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# Plot of peopleCount over time
plt.figure(figsize=(100,10))
data.set_index('Datetime')['peopleCount'].plot()
plt.title('peopleCount over time')
plt.xlabel('Datetime')
plt.ylabel('peopleCount')
plt.grid(True)
plt.tight_layout()
plt.show()

data_info, summary_statistics, unique_counts

# Count plots for categorical variables
categorical_variables = ['floor', 'building', 'workspace', 'department']

fig, axs = plt.subplots(nrows=len(categorical_variables), figsize=(9, 5*len(categorical_variables)))

for i, var in enumerate(categorical_variables):
    sns.countplot(y=var, data=data, ax=axs[i])
    axs[i].set_title(f'Distribution of {var}')
    axs[i].grid(True)

plt.tight_layout()
plt.show()

# Average peopleCount by hour
plt.figure(figsize=(10,6))
data.groupby('hour')['peopleCount'].mean().plot(kind='bar')
plt.title('Average peopleCount by Hour')
plt.xlabel('Hour')
plt.ylabel('Average peopleCount')
plt.grid(True)
plt.show()

# Average peopleCount by day of week
plt.figure(figsize=(10,6))
data.groupby('dayofweek')['peopleCount'].mean().plot(kind='bar')
plt.title('Average peopleCount by Day of Week')
plt.xlabel('Day of Week')
plt.ylabel('Average peopleCount')
plt.grid(True)
plt.show()

# Average peopleCount by month
plt.figure(figsize=(10,6))
data.groupby('month')['peopleCount'].mean().plot(kind='bar')
plt.title('Average peopleCount by Month')
plt.xlabel('Month')
plt.ylabel('Average peopleCount')
plt.grid(True)
plt.show()

# Average peopleCount by department
plt.figure(figsize=(10,6))
data.groupby('department')['peopleCount'].mean().plot(kind='bar')
plt.title('Average peopleCount by Department')
plt.xlabel('Department')
plt.ylabel('Average peopleCount')
plt.grid(True)
plt.show()

# Correlation matrix
corr = data.corr()

# Plot correlation matrix
plt.figure(figsize=(10,8))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

# Create a day-night indicator: 1 for day (8am-6pm), 0 for night
data['day_night'] = ((data['hour'] >= 8) & (data['hour'] <= 18)).astype(int)

# Average peopleCount by day-night
day_night_avg = data.groupby('day_night')['peopleCount'].mean()

# Busiest and least busy hour of day
hour_avg = data.groupby('hour')['peopleCount'].mean()
busiest_hour = hour_avg.idxmax()
least_busy_hour = hour_avg.idxmin()

day_night_avg, busiest_hour, least_busy_hour























# Overview of the data
df_final.info()

# Statistical summary of numerical columns
df_final.describe()

# Generate summary statistics for the categorical columns
df_final.describe(include=['O'])

# Checking for missing values
df_final.isnull().sum()

"""Summary of the Final Dataset

The final dataset contains the following information:

- Number of Entries: 63,986
- Number of Columns: 14

Column Information:
- Categorical Columns: 'sensorId', 'floor', 'building', 'name', 'workspace', 'department'
- Numerical Columns: 'peopleCount', 'timezoneOffset', 'posX', 'posY', 'height', 'width', 'capacity'
- Datetime Column: 'Datetime' (in datetime format)

Missing Values: None

The dataset provides valuable information about the sensors, including their unique identifiers ('sensorId'), the number of people detected ('peopleCount'), the location details (floor, building, posX, posY), dimensions (height, width), workspace information (workspace, capacity), and the department associated with the workspace ('department').

##**Observations from the Visualizations**
"""

# Distribution of 'peopleCount'
plt.figure(figsize=(12, 6))
sns.histplot(df_final['peopleCount'], kde=False, bins=30)
plt.title('Distribution of peopleCount')
plt.show()

# Count plot for 'floor'
plt.figure(figsize=(12, 6))
sns.countplot(data=df_final, x='floor', order = df_final['floor'].value_counts().index)
plt.title('Count of Entries by Floor')
plt.xticks(rotation=90)
plt.show()

# Count plot for 'building'
plt.figure(figsize=(12, 6))
sns.countplot(data=df_final, x='building', order = df_final['building'].value_counts().index)
plt.title('Count of Entries by Building')
plt.xticks(rotation=90)
plt.show()

# Count plot for 'workspace'
plt.figure(figsize=(12, 6))
sns.countplot(data=df_final, x='workspace', order = df_final['workspace'].value_counts().index)
plt.title('Count of Entries by Workspace')
plt.xticks(rotation=90)
plt.show()

# Count plot for 'department'
plt.figure(figsize=(12, 6))
sns.countplot(data=df_final, x='department', order = df_final['department'].value_counts().index)
plt.title('Count of Entries by Department')
plt.xticks(rotation=90)
plt.show()

# Variation in 'peopleCount' over time
plt.figure(figsize=(12, 6))
df_final.set_index('Datetime')['peopleCount'].plot()
plt.title('Variation in peopleCount Over Time')
plt.show()

# Correlation heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(df_final[['peopleCount', 'timezoneOffset', 'posX', 'posY', 'height', 'width', 'capacity']].corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""
Here are the observations from the visualizations:

1. Distribution of 'peopleCount': The distribution of 'peopleCount' is heavily skewed to the right, with most of the counts being less than 10. This suggests that the majority of sensor readings indicate the absence or low presence of people.

2. Count of Entries by Floor: The distribution of entries across floors is uneven. 'Floor 5' has the highest number of entries, indicating that it is the most densely monitored floor. On the other hand, 'Floor 4' has the least number of entries, suggesting it may have lower monitoring coverage.

3. Count of Entries by Building: The distribution of entries across buildings is also uneven. 'REM Tower5' has the most entries, indicating it is the most extensively monitored building. Conversely, 'REM Tower8' has the least number of entries, suggesting it may have lower monitoring coverage.

4. Count of Entries by Workspace: The distribution of entries across workspaces shows that 'Desks' is the workspace with the highest number of entries, indicating it is the most monitored workspace. 'Meeting Rooms' also has a significant number of entries. 'Breakout Areas' and 'Kitchens' have fewer entries, suggesting they may have lower monitoring coverage.

5. Count of Entries by Department: The distribution of entries across departments shows that 'BMS' has the highest number of entries, followed by 'HR' and 'FINANCE'. This indicates that these departments are the most monitored. 'EXEC' has the least number of entries, suggesting it may have lower monitoring coverage.

6. Variation in 'peopleCount' Over Time: The number of people detected by the sensors appears to fluctuate over time, with some periods showing higher counts than others. This suggests temporal variations in human activity within the monitored areas.

7. Correlation Heatmap: The heatmap shows the correlation between different numerical variables. It appears that there is no strong correlation between 'peopleCount' and the other numerical variables, indicating that the presence or absence of people is not strongly influenced by these factors.

These observations provide valuable insights into the distribution of 'peopleCount', the coverage across different floors, buildings, workspaces, and departments, as well as the temporal variations and correlations with other variables.
"""











